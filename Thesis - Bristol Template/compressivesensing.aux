\relax 
\bibstyle{plain}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {section}{\numberline {0.1}Introduction and Preliminaries}{1}}
\newlabel{sec:intro}{{0.1}{1}}
\citation{watkincandes}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.1}RIP and Stable Embeddings}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {0.1.1}{\ignorespaces A visualisation of the Compressive Sensing problem as an under-determined system}}{3}}
\newlabel{l1l2}{{0.1.1}{3}}
\citation{shalev2014understanding}
\newlabel{def:RIP}{{0.1.2}{4}}
\newlabel{def:RIP}{{0.1.2}{4}}
\newlabel{def:d-stable}{{0.1.7}{5}}
\citation{Candes2006}
\citation{davenport2010signal}
\citation{baraniuk2008simple}
\citation{baraniuk2008simple}
\newlabel{minsamples}{{0.1.1}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.2}Random Matrix Constructions}{7}}
\newlabel{sec:mtx-contruction}{{0.1.2}{7}}
\newlabel{cond:norm-pres}{{1}{7}}
\newlabel{cond:sub-Gauss}{{2}{7}}
\newlabel{cond:sub-Gauss concetration}{{0.1.2.10}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.3}Wishart Matrices}{7}}
\citation{levequeMatrices}
\newlabel{remark: exp AtA}{{0.1.16}{8}}
\citation{Chen1998a}
\citation{tibshirani1996regression}
\citation{hastie2005elements}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.4}Reconstruction Algorithms}{9}}
\newlabel{program:bp}{{0.1.4.16}{9}}
\newlabel{program:lasso}{{0.1.4.17}{9}}
\newlabel{soln:lasso}{{0.1.4.18}{9}}
\newlabel{program:ridge}{{0.1.4.19}{9}}
\citation{Tibshirani1996}
\citation{Tibshirani1996}
\newlabel{soln:ridge}{{0.1.4.20}{10}}
\newlabel{program:ell0}{{0.1.4.21}{10}}
\newlabel{soln:l0}{{0.1.4.22}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {0.1.2}{\ignorespaces Solutions to the Compressive Sensing optimisation problem intersect the \(l_1\) norm the points where all components (but one) of the vector are zero (i.e. it is sparsity promoting) \cite  {Tibshirani1996}}}{10}}
\newlabel{fig:l1l2}{{0.1.2}{10}}
\citation{candes2007dantzig}
\citation{candes2007dantzig}
\citation{bickel2009simultaneous}
\newlabel{program:enat}{{0.1.4.23}{11}}
\newlabel{program:enat}{{0.1.4.24}{11}}
\citation{donoho2009message}
\citation{figueiredo2003algorithm}
\citation{tropp2007signal}
\citation{wen2013improved}
\@writefile{lof}{\contentsline {figure}{\numberline {0.1.3}{\ignorespaces The Iterative Soft Thresholding Algorithm}}{13}}
\newlabel{alg:IST}{{0.1.3}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {0.1.4}{\ignorespaces The OMP recovery algorithm}}{14}}
\newlabel{alg:omp}{{0.1.4}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {0.1.5}{\ignorespaces The AMP recovery algorithm}}{14}}
\newlabel{alg:amp}{{0.1.5}{14}}
\citation{Tibshirani1996}
\citation{Tibshirani1996}
\citation{Tibshirani1996}
\newlabel{CSequation}{{0.1.4}{15}}
\citation{Baron2010}
\@writefile{lof}{\contentsline {figure}{\numberline {0.1.6}{\ignorespaces The Laplace (\(l_1\)-norm, bold line) and Normal (\(l_2\)-norm, dotted line) densities. Note that the Laplace density is sparsity promoting as it penalises solutions away from zero more than the Gaussian density. \cite  {Tibshirani1996}}}{16}}
\newlabel{laplacenormal}{{0.1.6}{16}}
\citation{Ji2008}
\citation{Yedidia2011}
\citation{metzler2014denoising}
\@writefile{lof}{\contentsline {figure}{\numberline {0.1.7}{\ignorespaces The hierarchical model for the Bayesian CS formulation \cite  {Ji2008}}}{17}}
\newlabel{bayesiancs}{{0.1.7}{17}}
\citation{Zhang2011b}
\citation{Zhang2011b}
\citation{mishali2010theory}
\@writefile{toc}{\contentsline {section}{\numberline {0.2}Compressive Sensing Architechtures}{18}}
\newlabel{sec:sensingmodel}{{0.2}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.2.1}Modulated Wideband Converter}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {0.2.8}{\ignorespaces Mse vs SNR for the sensing model, with AWGN only, showing the performance of distributed and centralised solvers}}{19}}
\newlabel{msevssnr0}{{0.2.8}{19}}
\newlabel{system}{{0.2.1.36}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.2.2}Random Demodulator}{20}}
\bibdata{thesis}
\bibcite{baraniuk2008simple}{1}
\bibcite{Baron2010}{2}
\bibcite{bickel2009simultaneous}{3}
\bibcite{candes2007dantzig}{4}
\bibcite{Candes2006}{5}
\bibcite{Chen1998a}{6}
\bibcite{davenport2010signal}{7}
\bibcite{donoho2009message}{8}
\bibcite{figueiredo2003algorithm}{9}
\bibcite{hastie2005elements}{10}
\bibcite{Ji2008}{11}
\bibcite{levequeMatrices}{12}
\bibcite{metzler2014denoising}{13}
\bibcite{mishali2010theory}{14}
\bibcite{shalev2014understanding}{15}
\bibcite{Tibshirani1996}{16}
\bibcite{tibshirani1996regression}{17}
\bibcite{tropp2007signal}{18}
\bibcite{wen2013improved}{19}
\bibcite{Yedidia2011}{20}
\bibcite{Zhang2011b}{21}
