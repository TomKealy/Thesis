\relax 
\citation{akan2009cognitive}
\citation{Candes2006}
\citation{mishali2010theory}
\citation{tropp2010beyond}
\citation{Zhang2011b}
\citation{tian2006wavelet}
\@writefile{toc}{\contentsline {section}{\numberline {\normalfont  0.\normalfont  14}Introduction}{53}}
\citation{tian2006wavelet}
\citation{ling2014dlm}
\citation{mota2013d}
\@writefile{toc}{\contentsline {section}{\numberline {\normalfont  0.\normalfont  15}Signal Model}{54}}
\newlabel{basis}{{\normalfont  0.\normalfont  15.0.150}{54}}
\newlabel{basis-expansion}{{\normalfont  0.\normalfont  15.0.153}{55}}
\newlabel{def:a}{{\normalfont  0.\normalfont  15.1}{55}}
\@writefile{toc}{\contentsline {section}{\numberline {\normalfont  0.\normalfont  16}Sensing Model}{55}}
\newlabel{sec:sensingmodel}{{\normalfont  0.\normalfont  16}{55}}
\newlabel{dist_system}{{\normalfont  0.\normalfont  16.0.158}{55}}
\newlabel{system}{{\normalfont  0.\normalfont  16.0.159}{56}}
\newlabel{opt}{{\normalfont  0.\normalfont  16.0.160}{56}}
\@writefile{toc}{\contentsline {section}{\numberline {\normalfont  0.\normalfont  17}Constrained Optimisation on Graphs}{56}}
\newlabel{sec:opt-on-graphs}{{\normalfont  0.\normalfont  17}{56}}
\citation{Boyd2010a}
\newlabel{barxc}{{\normalfont  0.\normalfont  17.0.162}{57}}
\newlabel{constrainedbp}{{\normalfont  0.\normalfont  17.0.163}{57}}
\newlabel{compact-constraints}{{\normalfont  0.\normalfont  17.0.164}{57}}
\newlabel{constrainedbp1}{{\normalfont  0.\normalfont  17.0.165}{57}}
\citation{Boyd2010a}
\newlabel{aug-lagrange}{{\normalfont  0.\normalfont  17.0.166}{58}}
\@writefile{lof}{\contentsline {figure}{\numberline {\normalfont  0.\normalfont  17.27}{\ignorespaces The algorithm at Node \(j\)\relax }}{59}}
\newlabel{DADMM}{{\normalfont  0.\normalfont  17.27}{59}}
\newlabel{generic-iterations}{{\normalfont  0.\normalfont  17.0.170}{60}}
\newlabel{dadmm_algo_lasso}{{\normalfont  0.\normalfont  17.0.175}{60}}
\citation{chen1998atomic}
\citation{bazerque2008}
\citation{bazerque2008}
\@writefile{toc}{\contentsline {section}{\numberline {\normalfont  0.\normalfont  18}Results}{61}}
\newlabel{sec:results}{{\normalfont  0.\normalfont  18}{61}}
\citation{DADMMconvergence}
\citation{nishihara2015general}
\citation{su2014differential}
\citation{mokhtari2015dqm}
\citation{ling2014dlm}
\@writefile{lof}{\contentsline {figure}{\numberline {\normalfont  0.\normalfont  18.28}{\ignorespaces Left to right: (a) The original signal. (b) The gradient \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {def:a}\unskip \@@italiccorr )}} of the original signal. (c) Recovery using DADMM, 1000 iterations, \(\sigma ^2_n = 5\). (d) Recovery using DADMM, 1000 iterations, \(\sigma ^2_n = 20\) \relax }}{62}}
\newlabel{different_sigs}{{\normalfont  0.\normalfont  18.28}{62}}
\@writefile{toc}{\contentsline {section}{\numberline {\normalfont  0.\normalfont  19}Conclusions}{62}}
\citation{goldstein2014fast}
\@writefile{lof}{\contentsline {figure}{\numberline {\normalfont  0.\normalfont  18.29}{\ignorespaces MSE vs SNR for the sensing model showing the performance of distributed and centralised solvers. The performance of DADMM is consistently within \(10^{-2}\) of ADMM, and within the error bars of ADMM at low SNRs. The variance of estimates produced by DADMM is larger than ADMM, due to nodes performing computations on a subset of data. Both estimates are consistently within \(10^{-1}\) of the optimal solution, which is sufficient to classify occupied bands.\relax }}{63}}
\newlabel{msevssnr0}{{\normalfont  0.\normalfont  18.29}{63}}
\@writefile{lof}{\contentsline {figure}{\numberline {\normalfont  0.\normalfont  18.30}{\ignorespaces The progress of the distributed solver as a function of the number of iterations, with different values of the regression parameter \( \lambda \). For a fixed \( \lambda \) there is a single unique optimal solution, with higher \( \lambda \) favouring sparser solutions. The convergence of DADMM is slowed by smaller \( \lambda \). This is intuitive: solutions with fewer non-zero components should be identified in fewer iterations.\relax }}{64}}
\newlabel{fig:differentLambda}{{\normalfont  0.\normalfont  18.30}{64}}
\@setckpt{cswirelesspaper_new_basis}{
\setcounter{page}{65}
\setcounter{equation}{179}
\setcounter{enumi}{6}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{0}
\setcounter{section}{19}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{30}
\setcounter{table}{1}
\setcounter{NAT@ctr}{0}
\setcounter{parentequation}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{lofdepth}{1}
\setcounter{lotdepth}{1}
\setcounter{AlgoLine}{0}
\setcounter{algocfline}{0}
\setcounter{algocfproc}{0}
\setcounter{algocf}{0}
\setcounter{eqn}{0}
\setcounter{thm}{1}
\setcounter{defn}{6}
\setcounter{theorem}{0}
\setcounter{condition}{0}
}
